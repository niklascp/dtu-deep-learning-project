{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model - Random Forest with geo-spatial dummy variables and kinematic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from infostop import Infostop\n",
    "import pyproj\n",
    "import sklearn\n",
    "import pickle\n",
    "import torch\n",
    "sys.path.append('./src')\n",
    "from data_utils import *\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleansing - Cut-off parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_cutoff_speed = 45\n",
    "seq_cutoff_time = 60\n",
    "filter_seq = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup machine learning baselines\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Random Forest\"\n",
    "    #, \"Decision Tree\"\n",
    "    #, \"Nearest Neighbors\"\n",
    "    #, \"Neural Net\", \"AdaBoost\"\n",
    "    #, \"Naive Bayes\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=100\n",
    "                           , criterion = 'entropy'\n",
    "                           , class_weight='balanced'\n",
    "                           , max_depth= 8\n",
    "                           , max_features= 'auto'\n",
    "                           , random_state=0\n",
    "                           , n_jobs=-1\n",
    "                           , oob_score=True\n",
    "                           , verbose=1)\n",
    "    #, DecisionTreeClassifier(max_depth=5, class_weight=\"balanced\")\n",
    "    #, KNeighborsClassifier(3)\n",
    "    #, MLPClassifier(alpha=1, max_iter=1000)\n",
    "    #, AdaBoostClassifier()\n",
    "    #, GaussianNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load same training and test set of the Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "\n",
    "        def __init__(self, df, filter_seq=filter_seq):\n",
    "            self.seq = np.stack([np.roll(df[['delta_d', 'bearing', 'f_highway_motorway','f_traffic_signals','f_bus_stops','f_landuse_meadow','f_landuse_residential','f_landuse_industrial','f_landuse_commercial','f_shop','f_railways','f_railways_station','f_subway']].values, i, axis = 0) for i in range(filter_seq, -1, -1)], axis = 1)\n",
    "            self.seq = self.seq[df['segment_ix'] >= filter_seq]\n",
    "\n",
    "            self.labels = df[df['segment_ix'] >= filter_seq]['label'].values        \n",
    "            self.user_id = df[df['segment_ix'] >= filter_seq]['user'].values\n",
    "            tod = df[df['segment_ix'] >= filter_seq]['tod'].values\n",
    "            self.tod_one_hot = np.eye(5)[tod]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, key):\n",
    "            return self.seq[key], self.tod_one_hot[key], self.labels[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the sequence of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "classification_test_performance = []\n",
    "training_time = []\n",
    "prediction_time = []\n",
    "number_list=np.arange(0,12).tolist()\n",
    "random.Random(17).shuffle(number_list)\n",
    "print(number_list)\n",
    "#number_list = [10, 4, 6, 8, 1, 9, 3, 7, 5, 0, 2, 11] #already randomized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the 12-fold cross validation, rotating each user at the test set, while the others are on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition: [3, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 10\n",
      "Fold 0, Train [3, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8], Test [10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   36.2s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 74.09675312042236\n",
      "Prediction lasted 0.5803370475769043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.96      0.54      0.69      1150\n",
      "        Stop       0.44      0.94      0.60       451\n",
      "\n",
      "    accuracy                           0.65      1601\n",
      "   macro avg       0.70      0.74      0.64      1601\n",
      "weighted avg       0.81      0.65      0.66      1601\n",
      "\n",
      "Train partition: [10, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 3\n",
      "Fold 1, Train [10, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8], Test [3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   44.8s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 60.3629195690155\n",
      "Prediction lasted 0.2421116828918457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.89      0.68      0.77     21110\n",
      "        Stop       0.89      0.97      0.93     58167\n",
      "\n",
      "    accuracy                           0.89     79277\n",
      "   macro avg       0.89      0.82      0.85     79277\n",
      "weighted avg       0.89      0.89      0.89     79277\n",
      "\n",
      "Train partition: [10, 3, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 0\n",
      "Fold 2, Train [10, 3, 2, 7, 11, 1, 9, 5, 4, 6, 8], Test [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   24.3s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 37.411975145339966\n",
      "Prediction lasted 0.11748170852661133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.91      0.73      0.81     20196\n",
      "        Stop       0.92      0.98      0.95     64268\n",
      "\n",
      "    accuracy                           0.92     84464\n",
      "   macro avg       0.91      0.85      0.88     84464\n",
      "weighted avg       0.92      0.92      0.91     84464\n",
      "\n",
      "Train partition: [10, 3, 0, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 2\n",
      "Fold 3, Train [10, 3, 0, 7, 11, 1, 9, 5, 4, 6, 8], Test [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   44.8s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 80.90433835983276\n",
      "Prediction lasted 0.8917820453643799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.75      0.85      0.80     43225\n",
      "        Stop       0.90      0.83      0.87     72339\n",
      "\n",
      "    accuracy                           0.84    115564\n",
      "   macro avg       0.83      0.84      0.83    115564\n",
      "weighted avg       0.85      0.84      0.84    115564\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 7\n",
      "Fold 4, Train [10, 3, 0, 2, 11, 1, 9, 5, 4, 6, 8], Test [7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   26.2s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 42.226372957229614\n",
      "Prediction lasted 0.11041069030761719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.79      0.31      0.45      7897\n",
      "        Stop       0.23      0.71      0.35      2295\n",
      "\n",
      "    accuracy                           0.40     10192\n",
      "   macro avg       0.51      0.51      0.40     10192\n",
      "weighted avg       0.66      0.40      0.43     10192\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 11\n",
      "Fold 5, Train [10, 3, 0, 2, 7, 1, 9, 5, 4, 6, 8], Test [11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   33.4s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 70.74363398551941\n",
      "Prediction lasted 0.6856362819671631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.88      0.52      0.65     11675\n",
      "        Stop       0.73      0.95      0.83     16340\n",
      "\n",
      "    accuracy                           0.77     28015\n",
      "   macro avg       0.81      0.73      0.74     28015\n",
      "weighted avg       0.79      0.77      0.75     28015\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 9, 5, 4, 6, 8]\n",
      "Test partition: 1\n",
      "Fold 6, Train [10, 3, 0, 2, 7, 11, 9, 5, 4, 6, 8], Test [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   23.7s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 40.880995750427246\n",
      "Prediction lasted 0.7924036979675293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.89      0.76      0.82    182626\n",
      "        Stop       0.91      0.96      0.94    462039\n",
      "\n",
      "    accuracy                           0.91    644665\n",
      "   macro avg       0.90      0.86      0.88    644665\n",
      "weighted avg       0.90      0.91      0.90    644665\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 5, 4, 6, 8]\n",
      "Test partition: 9\n",
      "Fold 7, Train [10, 3, 0, 2, 7, 11, 1, 5, 4, 6, 8], Test [9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   26.5s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 42.52719330787659\n",
      "Prediction lasted 0.10700416564941406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.44      0.19      0.27        42\n",
      "        Stop       0.37      0.67      0.48        30\n",
      "\n",
      "    accuracy                           0.39        72\n",
      "   macro avg       0.41      0.43      0.37        72\n",
      "weighted avg       0.41      0.39      0.35        72\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 4, 6, 8]\n",
      "Test partition: 5\n",
      "Fold 8, Train [10, 3, 0, 2, 7, 11, 1, 9, 4, 6, 8], Test [5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   49.0s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 86.53653955459595\n",
      "Prediction lasted 0.6803915500640869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.70      0.65      0.67      4259\n",
      "        Stop       0.89      0.91      0.90     13069\n",
      "\n",
      "    accuracy                           0.85     17328\n",
      "   macro avg       0.79      0.78      0.79     17328\n",
      "weighted avg       0.84      0.85      0.84     17328\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 6, 8]\n",
      "Test partition: 4\n",
      "Fold 9, Train [10, 3, 0, 2, 7, 11, 1, 9, 5, 6, 8], Test [4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 28.16252851486206\n",
      "Prediction lasted 0.46804285049438477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.62      0.85      0.72     77537\n",
      "        Stop       0.96      0.88      0.92    340189\n",
      "\n",
      "    accuracy                           0.87    417726\n",
      "   macro avg       0.79      0.87      0.82    417726\n",
      "weighted avg       0.90      0.87      0.88    417726\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 8]\n",
      "Test partition: 6\n",
      "Fold 10, Train [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 8], Test [6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   25.5s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 52.37347102165222\n",
      "Prediction lasted 0.41849851608276367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.87      0.63      0.73     12477\n",
      "        Stop       0.15      0.41      0.22      1983\n",
      "\n",
      "    accuracy                           0.60     14460\n",
      "   macro avg       0.51      0.52      0.47     14460\n",
      "weighted avg       0.77      0.60      0.66     14460\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 6]\n",
      "Test partition: 8\n",
      "Fold 11, Train [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 6], Test [8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   49.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 80.559321641922\n",
      "Prediction lasted 0.10925030708312988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.95      0.45      0.61     12727\n",
      "        Stop       0.21      0.86      0.34      2211\n",
      "\n",
      "    accuracy                           0.51     14938\n",
      "   macro avg       0.58      0.66      0.47     14938\n",
      "weighted avg       0.84      0.51      0.57     14938\n",
      "\n",
      "MEAN = 0.6787218124788866, STDEV = 0.1882611444096775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,12):\n",
    "    # Train-test split\n",
    "    print(f'Train partition: {number_list[0:k]+number_list[k+1:]}')\n",
    "    print(f'Test partition: {number_list[k]}')\n",
    "    user_train = train = number_list[0:k]+number_list[k+1:]\n",
    "    user_test = test = [number_list[k]]\n",
    "    \n",
    "    # Collect features of each user\n",
    "    print(f'Fold {k}, Train {train}, Test {test}')\n",
    "    data_train = pd.concat([create_data_frame(*load_user_data(user,load_web_mercator = True, load_GPS = True, load_Dummies=True), segmentation=True, seq_cutoff_time = seq_cutoff_time, seq_cutoff_speed = seq_cutoff_speed) for user in user_train]).reset_index(drop=True)\n",
    "    data_test = pd.concat([create_data_frame(*load_user_data(user,load_web_mercator = True, load_GPS = True, load_Dummies=True), segmentation=True, seq_cutoff_time = seq_cutoff_time, seq_cutoff_speed = seq_cutoff_speed) for user in user_test]).reset_index(drop=True)\n",
    "    data_train = data_train[data_train['segment_ix'] >= filter_seq]\n",
    "    data_test = data_test[data_test['segment_ix'] >= filter_seq]\n",
    "    \n",
    "    #Prepare the sequences of features for training set\n",
    "    TimeSeries = TensorDataset(pd.concat([data_train]).reset_index(drop=True))\n",
    "    XY_tr = np.array([np.concatenate(((TS[0]).reshape(-1),TS[1],TS[2].reshape(-1)), axis=0) for TS in TimeSeries]).reshape(-1,84)\n",
    "    \n",
    "    #Shuffle training set to ensure a iid when training\n",
    "    np.random.shuffle(XY_tr)\n",
    "    X_tr = XY_tr[:,0:XY_tr.shape[1]-1]\n",
    "    X_tr = StandardScaler().fit_transform(X_tr)\n",
    "    Y_tr = XY_tr[:,-1]\n",
    "    \n",
    "    #Prepare the sequences of features for test set\n",
    "    TimeSeries = TensorDataset(pd.concat([data_test]).reset_index(drop=True))\n",
    "    X_te = np.array([np.concatenate(((TS[0]).reshape(-1),TS[1]), axis=0) for TS in TimeSeries]).reshape(-1,83)\n",
    "    X_te = StandardScaler().fit_transform(X_te)\n",
    "    Y_te = TimeSeries[:][2]\n",
    "    \n",
    "    \n",
    "    # iterate over classifiers (only RF in this case)\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        startTraining = time.time()\n",
    "        clf.fit(X_tr, Y_tr)\n",
    "        endTraining = time.time()\n",
    "        Y_pred = clf.predict(X_te)\n",
    "        endPrediction = time.time()\n",
    "        print('REPORT: '+name)\n",
    "        cr=classification_report(Y_te, Y_pred, target_names=['Motion','Stop'],output_dict=True)\n",
    "        classification_test_performance.append(cr)\n",
    "        training_time.append(endTraining-startTraining)\n",
    "        prediction_time.append(endPrediction-endTraining)\n",
    "        print(f'Training lasted {training_time[-1]}')\n",
    "        print(f'Prediction lasted {prediction_time[-1]}')\n",
    "        print(classification_report(Y_te, Y_pred, target_names=['Motion','Stop'],output_dict=False))\n",
    "    \n",
    "\n",
    "F1_macro_AVG = []\n",
    "for cr in classification_test_performance:\n",
    "    F1_macro_AVG.append(cr['macro avg']['f1-score'])\n",
    "print(f'MEAN = {np.mean(F1_macro_AVG)}, STDEV = {np.std(F1_macro_AVG)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN = 0.6787218124788866, WEIGHTED AVG = 0.8397143375335308, STDEV = 0.1882611444096775\n"
     ]
    }
   ],
   "source": [
    "np.save('classification_test_RF12foldDummies.npy',classification_test_performance)\n",
    "F1_macro_AVG = []\n",
    "F1_weighted_AVG = []\n",
    "for cr in classification_test_performance:\n",
    "    F1_macro_AVG.append(cr['macro avg']['f1-score'])\n",
    "    F1_weighted_AVG.append(cr['weighted avg']['f1-score'])\n",
    "supports = [cf['macro avg']['support'] for cf in classification_test_performance]\n",
    "print(f'MEAN = {np.mean(F1_macro_AVG)}, WEIGHTED AVG = {np.sum([F1_macro_AVG[i]*supports[i] for i in range(0,len(F1_macro_AVG))])/(np.sum(supports))}, STDEV = {np.std(F1_macro_AVG)}')\n",
    "#print(f'MEAN = {np.mean(F1_weighted_AVG)}, WEIGHTED AVG = {np.sum([F1_weighted_AVG[i]*supports[i] for i in range(0,len(F1_weighted_AVG))])/(np.sum(supports))}, STDEV = {np.std(F1_weighted_AVG)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [i for i in zip(F1_macro_AVG, F1_weighted_AVG, supports)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('resRF12foldDummies.npy',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6431044142597795,\n",
       " 0.8501833732989095,\n",
       " 0.8771180308462088,\n",
       " 0.8329310911612731,\n",
       " 0.39795151294638786,\n",
       " 0.7403114450411816,\n",
       " 0.8785576934047628,\n",
       " 0.37142857142857144,\n",
       " 0.7860072461914216,\n",
       " 0.8183128823335528,\n",
       " 0.4739980530750306,\n",
       " 0.47475743575955903]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in F1_macro_AVG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696.7860429286957"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.20335054397583"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(prediction_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
