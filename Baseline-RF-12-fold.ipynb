{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model - Random Forest with kinematic features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from infostop import Infostop\n",
    "import pyproj\n",
    "import sklearn\n",
    "import pickle\n",
    "import torch\n",
    "sys.path.append('./src')\n",
    "from data_utils import *\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleansing - Cut-off parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_cutoff_speed = 45\n",
    "seq_cutoff_time = 60\n",
    "filter_seq = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup machine learning baselines\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Optimal parameters for Random Forest Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Random Forest\"\n",
    "    #, \"Decision Tree\"\n",
    "    #, \"Nearest Neighbors\"\n",
    "    #, \"Neural Net\", \"AdaBoost\"\n",
    "    #, \"Naive Bayes\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators = 500\n",
    "                           , criterion = 'gini'\n",
    "                           , class_weight='balanced'\n",
    "                           , max_depth= 8\n",
    "                           , max_features= 'auto'\n",
    "                           , random_state=0\n",
    "                           , n_jobs=-1\n",
    "                           , oob_score=True\n",
    "                           , verbose=1)\n",
    "    #, DecisionTreeClassifier(max_depth=5, class_weight=\"balanced\")\n",
    "    #, KNeighborsClassifier(3)\n",
    "    #, MLPClassifier(alpha=1, max_iter=1000)\n",
    "    #, AdaBoostClassifier()\n",
    "    #, GaussianNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load same training and test set of the Artificial Neural Networks¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "\n",
    "        def __init__(self, df, filter_seq=filter_seq):\n",
    "            self.seq = np.stack([np.roll(df[['delta_d', 'bearing']].values, i, axis = 0) for i in range(filter_seq, -1, -1)], axis = 1)\n",
    "            self.seq = self.seq[df['segment_ix'] >= filter_seq]\n",
    "\n",
    "            self.labels = df[df['segment_ix'] >= filter_seq]['label'].values        \n",
    "            self.user_id = df[df['segment_ix'] >= filter_seq]['user'].values\n",
    "            tod = df[df['segment_ix'] >= filter_seq]['tod'].values\n",
    "            self.tod_one_hot = np.eye(5)[tod]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, key):\n",
    "            return self.seq[key], self.tod_one_hot[key], self.labels[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the sequence of users¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "classification_test_performance = []\n",
    "training_time = []\n",
    "prediction_time = []\n",
    "number_list=np.arange(0,12).tolist()\n",
    "random.Random(17).shuffle(number_list)\n",
    "print(number_list)\n",
    "#number_list = [10, 4, 6, 8, 1, 9, 3, 7, 5, 0, 2, 11] #already randomized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the 12-fold cross validation, rotating each user at the test set, while the others are on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition: [3, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 10\n",
      "Fold 0, Train [3, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8], Test [10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 209.87211418151855\n",
      "Prediction lasted 0.2108592987060547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.90      0.52      0.66      1150\n",
      "        Stop       0.41      0.86      0.56       451\n",
      "\n",
      "    accuracy                           0.61      1601\n",
      "   macro avg       0.66      0.69      0.61      1601\n",
      "weighted avg       0.76      0.61      0.63      1601\n",
      "\n",
      "Train partition: [10, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 3\n",
      "Fold 1, Train [10, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8], Test [3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 187.33097863197327\n",
      "Prediction lasted 0.3110077381134033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.88      0.68      0.77     21110\n",
      "        Stop       0.89      0.97      0.93     58167\n",
      "\n",
      "    accuracy                           0.89     79277\n",
      "   macro avg       0.89      0.82      0.85     79277\n",
      "weighted avg       0.89      0.89      0.88     79277\n",
      "\n",
      "Train partition: [10, 3, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 0\n",
      "Fold 2, Train [10, 3, 2, 7, 11, 1, 9, 5, 4, 6, 8], Test [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 185.9017276763916\n",
      "Prediction lasted 0.31560611724853516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.91      0.72      0.81     20196\n",
      "        Stop       0.92      0.98      0.95     64268\n",
      "\n",
      "    accuracy                           0.92     84464\n",
      "   macro avg       0.92      0.85      0.88     84464\n",
      "weighted avg       0.92      0.92      0.91     84464\n",
      "\n",
      "Train partition: [10, 3, 0, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 2\n",
      "Fold 3, Train [10, 3, 0, 7, 11, 1, 9, 5, 4, 6, 8], Test [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 182.9311261177063\n",
      "Prediction lasted 2.532219409942627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.75      0.84      0.80     43225\n",
      "        Stop       0.90      0.83      0.87     72339\n",
      "\n",
      "    accuracy                           0.84    115564\n",
      "   macro avg       0.83      0.84      0.83    115564\n",
      "weighted avg       0.84      0.84      0.84    115564\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 7\n",
      "Fold 4, Train [10, 3, 0, 2, 11, 1, 9, 5, 4, 6, 8], Test [7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 180.24498867988586\n",
      "Prediction lasted 0.20838427543640137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.82      0.31      0.45      7897\n",
      "        Stop       0.24      0.77      0.37      2295\n",
      "\n",
      "    accuracy                           0.41     10192\n",
      "   macro avg       0.53      0.54      0.41     10192\n",
      "weighted avg       0.69      0.41      0.43     10192\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 11\n",
      "Fold 5, Train [10, 3, 0, 2, 7, 1, 9, 5, 4, 6, 8], Test [11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 150.08737659454346\n",
      "Prediction lasted 0.20920872688293457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.89      0.50      0.64     11675\n",
      "        Stop       0.73      0.96      0.83     16340\n",
      "\n",
      "    accuracy                           0.77     28015\n",
      "   macro avg       0.81      0.73      0.73     28015\n",
      "weighted avg       0.80      0.77      0.75     28015\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 9, 5, 4, 6, 8]\n",
      "Test partition: 1\n",
      "Fold 6, Train [10, 3, 0, 2, 7, 11, 9, 5, 4, 6, 8], Test [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   48.1s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 69.13757634162903\n",
      "Prediction lasted 1.8385474681854248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.91      0.73      0.81    182626\n",
      "        Stop       0.90      0.97      0.93    462039\n",
      "\n",
      "    accuracy                           0.90    644665\n",
      "   macro avg       0.90      0.85      0.87    644665\n",
      "weighted avg       0.90      0.90      0.90    644665\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 5, 4, 6, 8]\n",
      "Test partition: 9\n",
      "Fold 7, Train [10, 3, 0, 2, 7, 11, 1, 5, 4, 6, 8], Test [9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 154.49902319908142\n",
      "Prediction lasted 0.21431183815002441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.23      0.07      0.11        42\n",
      "        Stop       0.34      0.67      0.45        30\n",
      "\n",
      "    accuracy                           0.32        72\n",
      "   macro avg       0.28      0.37      0.28        72\n",
      "weighted avg       0.28      0.32      0.25        72\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 4, 6, 8]\n",
      "Test partition: 5\n",
      "Fold 8, Train [10, 3, 0, 2, 7, 11, 1, 9, 4, 6, 8], Test [5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 181.63563179969788\n",
      "Prediction lasted 0.3323478698730469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.71      0.64      0.67      4259\n",
      "        Stop       0.89      0.92      0.90     13069\n",
      "\n",
      "    accuracy                           0.85     17328\n",
      "   macro avg       0.80      0.78      0.79     17328\n",
      "weighted avg       0.84      0.85      0.84     17328\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 6, 8]\n",
      "Test partition: 4\n",
      "Fold 9, Train [10, 3, 0, 2, 7, 11, 1, 9, 5, 6, 8], Test [4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 144.2327880859375\n",
      "Prediction lasted 1.6469242572784424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.63      0.85      0.72     77537\n",
      "        Stop       0.96      0.88      0.92    340189\n",
      "\n",
      "    accuracy                           0.88    417726\n",
      "   macro avg       0.79      0.87      0.82    417726\n",
      "weighted avg       0.90      0.88      0.88    417726\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 8]\n",
      "Test partition: 6\n",
      "Fold 10, Train [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 8], Test [6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 199.61279678344727\n",
      "Prediction lasted 0.33044886589050293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.90      0.61      0.73     12477\n",
      "        Stop       0.19      0.55      0.28      1983\n",
      "\n",
      "    accuracy                           0.60     14460\n",
      "   macro avg       0.54      0.58      0.50     14460\n",
      "weighted avg       0.80      0.60      0.67     14460\n",
      "\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 6]\n",
      "Test partition: 8\n",
      "Fold 11, Train [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 6], Test [8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT: Random Forest\n",
      "Training lasted 195.97861075401306\n",
      "Prediction lasted 0.32500290870666504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Motion       0.96      0.41      0.58     12727\n",
      "        Stop       0.21      0.90      0.34      2211\n",
      "\n",
      "    accuracy                           0.48     14938\n",
      "   macro avg       0.59      0.66      0.46     14938\n",
      "weighted avg       0.85      0.48      0.54     14938\n",
      "\n",
      "MEAN = 0.6683957612182679, STDEV = 0.19935398504694668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done 386 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=32)]: Done 500 out of 500 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,12):\n",
    "    # Train-test split\n",
    "    print(f'Train partition: {number_list[0:k]+number_list[k+1:]}')\n",
    "    print(f'Test partition: {number_list[k]}')\n",
    "    user_train = train = number_list[0:k]+number_list[k+1:]\n",
    "    user_test = test = [number_list[k]]\n",
    "    \n",
    "    \n",
    "    # Collect features of each user\n",
    "    print(f'Fold {k}, Train {train}, Test {test}')\n",
    "    data_train = pd.concat([create_data_frame(*load_user_data(user,load_web_mercator = True, load_GPS = True), segmentation=True, seq_cutoff_time = seq_cutoff_time, seq_cutoff_speed = seq_cutoff_speed) for user in user_train]).reset_index(drop=True)\n",
    "    data_test = pd.concat([create_data_frame(*load_user_data(user,load_web_mercator = True, load_GPS = True), segmentation=True, seq_cutoff_time = seq_cutoff_time, seq_cutoff_speed = seq_cutoff_speed) for user in user_test]).reset_index(drop=True)\n",
    "    data_train = data_train[data_train['segment_ix'] >= filter_seq]\n",
    "    data_test = data_test[data_test['segment_ix'] >= filter_seq]\n",
    "    \n",
    "    #Prepare the sequences of features for training set\n",
    "    TimeSeries = TensorDataset(pd.concat([data_train]).reset_index(drop=True))\n",
    "    XY_tr = np.array([np.concatenate(((TS[0]).reshape(-1),TS[1],TS[2].reshape(-1)), axis=0) for TS in TimeSeries]).reshape(-1,18)\n",
    "    \n",
    "    #Shuffle training set to ensure a iid when training\n",
    "    np.random.shuffle(XY_tr)\n",
    "    X_tr = XY_tr[:,0:XY_tr.shape[1]-1]\n",
    "    X_tr = StandardScaler().fit_transform(X_tr)\n",
    "    Y_tr = XY_tr[:,-1]\n",
    "    \n",
    "    #Prepare the sequences of features for test set\n",
    "    TimeSeries = TensorDataset(pd.concat([data_test]).reset_index(drop=True))\n",
    "    X_te = np.array([np.concatenate(((TS[0]).reshape(-1),TS[1]), axis=0) for TS in TimeSeries]).reshape(-1,17)\n",
    "    X_te = StandardScaler().fit_transform(X_te)\n",
    "    Y_te = TimeSeries[:][2]\n",
    "    \n",
    "    \n",
    "    # iterate over classifiers (only RF in this case)\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        startTraining = time.time()\n",
    "        clf.fit(X_tr, Y_tr)\n",
    "        endTraining = time.time()\n",
    "        Y_pred = clf.predict(X_te)\n",
    "        endPrediction = time.time()\n",
    "        print('REPORT: '+name)\n",
    "        cr=classification_report(Y_te, Y_pred, target_names=['Motion','Stop'],output_dict=True)\n",
    "        classification_test_performance.append(cr)\n",
    "        training_time.append(endTraining-startTraining)\n",
    "        prediction_time.append(endPrediction-endTraining)\n",
    "        print(f'Training lasted {training_time[-1]}')\n",
    "        print(f'Prediction lasted {prediction_time[-1]}')\n",
    "        print(classification_report(Y_te, Y_pred, target_names=['Motion','Stop'],output_dict=False))\n",
    "    \n",
    "\n",
    "F1_macro_AVG = []\n",
    "for cr in classification_test_performance:\n",
    "    F1_macro_AVG.append(cr['macro avg']['f1-score'])\n",
    "print(f'MEAN = {np.mean(F1_macro_AVG)}, STDEV = {np.std(F1_macro_AVG)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN = 0.6683957612182679, WEIGHTED AVG = 0.8360022577493109, STDEV = 0.19935398504694668\n",
      "MEAN = 0.7108795148065797, WEIGHTED AVG = 0.8757207685679421, STDEV = 0.2038428688062497\n"
     ]
    }
   ],
   "source": [
    "np.save('classification_test_performanceRF12fold.npy',classification_test_performance)\n",
    "F1_macro_AVG = []\n",
    "F1_weighted_AVG = []\n",
    "for cr in classification_test_performance:\n",
    "    F1_macro_AVG.append(cr['macro avg']['f1-score'])\n",
    "    F1_weighted_AVG.append(cr['weighted avg']['f1-score'])\n",
    "supports = [cf['macro avg']['support'] for cf in classification_test_performance]\n",
    "print(f'MEAN = {np.mean(F1_macro_AVG)}, WEIGHTED AVG = {np.sum([F1_macro_AVG[i]*supports[i] for i in range(0,len(F1_macro_AVG))])/(np.sum(supports))}, STDEV = {np.std(F1_macro_AVG)}')\n",
    "print(f'MEAN = {np.mean(F1_weighted_AVG)}, WEIGHTED AVG = {np.sum([F1_weighted_AVG[i]*supports[i] for i in range(0,len(F1_weighted_AVG))])/(np.sum(supports))}, STDEV = {np.std(F1_weighted_AVG)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [i for i in zip(F1_macro_AVG, F1_weighted_AVG, supports)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('resRF12fold.npy',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.606728660279999,\n",
       " 0.8473783107634704,\n",
       " 0.876956702969576,\n",
       " 0.8302161621011173,\n",
       " 0.41003138494548014,\n",
       " 0.7322218799790635,\n",
       " 0.8695320918977578,\n",
       " 0.27926455566905006,\n",
       " 0.7864096590271031,\n",
       " 0.8208406078895909,\n",
       " 0.5025549258519956,\n",
       " 0.45861419324501196]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in F1_macro_AVG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2041.4647388458252"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.474868774414062"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(prediction_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
