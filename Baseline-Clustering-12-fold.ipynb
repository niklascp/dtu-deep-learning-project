{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model - Infostop with GPS positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from infostop import Infostop\n",
    "import pyproj\n",
    "import sklearn\n",
    "import pickle\n",
    "import torch\n",
    "sys.path.append('./src')\n",
    "from data_utils import *\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "classification_test_performance = []\n",
    "training_time = []\n",
    "prediction_time = []\n",
    "number_list=np.arange(0,12).tolist()\n",
    "random.Random(17).shuffle(number_list)\n",
    "print(number_list)\n",
    "#number_list = [10, 4, 6, 8, 1, 9, 3, 7, 5, 0, 2, 11] #already randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-fold Infostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition: [3, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 10\n",
      "Train partition: [10, 0, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 3\n",
      "Train partition: [10, 3, 2, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 0\n",
      "Train partition: [10, 3, 0, 7, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 2\n",
      "Train partition: [10, 3, 0, 2, 11, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 7\n",
      "Train partition: [10, 3, 0, 2, 7, 1, 9, 5, 4, 6, 8]\n",
      "Test partition: 11\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 9, 5, 4, 6, 8]\n",
      "Test partition: 1\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 5, 4, 6, 8]\n",
      "Test partition: 9\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 4, 6, 8]\n",
      "Test partition: 5\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 6, 8]\n",
      "Test partition: 4\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 8]\n",
      "Test partition: 6\n",
      "Train partition: [10, 3, 0, 2, 7, 11, 1, 9, 5, 4, 6]\n",
      "Test partition: 8\n"
     ]
    }
   ],
   "source": [
    "seq_cutoff_speed = 45\n",
    "seq_cutoff_time = 60\n",
    "filter_seq = 5\n",
    "for k in range(0,12):\n",
    "    print(f'Train partition: {number_list[0:k]+number_list[k+1:]}')\n",
    "    print(f'Test partition: {number_list[k]}')\n",
    "    user_train = train = number_list[0:k]+number_list[k+1:]\n",
    "    user_test = test = [number_list[k]]\n",
    "    \n",
    "    #data_train = pd.concat([create_data_frame(*load_user_data(user,load_web_mercator = True, load_GPS = True), segmentation=True, seq_cutoff_time = seq_cutoff_time, seq_cutoff_speed = seq_cutoff_speed) for user in user_train]).reset_index(drop=True)\n",
    "    data_test = pd.concat([create_data_frame(*load_user_data(user,load_web_mercator = True, load_GPS = True), segmentation=True, seq_cutoff_time = seq_cutoff_time, seq_cutoff_speed = seq_cutoff_speed) for user in user_test]).reset_index(drop=True)\n",
    "    #data_train = data_train[data_train['segment_ix'] >= filter_seq]\n",
    "    data_test = data_test[data_test['segment_ix'] >= filter_seq]\n",
    "    model = Infostop()\n",
    "    startPrediction = time.time()\n",
    "    labels = model.fit_predict(data_test[['lon', 'lat']].values)\n",
    "    endPrediction = time.time()\n",
    "    prediction_time.append(endPrediction-startPrediction)\n",
    "    pred = np.zeros_like(labels)\n",
    "    pred[labels >= 0] = 1\n",
    "    cr=classification_report(data_test['label'], pred, target_names = ['Motion','Stop'],output_dict=True)\n",
    "    classification_test_performance.append(cr)\n",
    "F1_macro_AVG = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN = 0.602154591003217, WEIGHTED AVG = 0.6535989161830201, STDEV = 0.14739750561616363\n",
      "MEAN = 0.6829053597361155, WEIGHTED AVG = 0.7639122059331971, STDEV = 0.15659593943266806\n"
     ]
    }
   ],
   "source": [
    "np.save('classification_test_performanceClust12fold.npy',classification_test_performance)\n",
    "F1_macro_AVG = []\n",
    "F1_weighted_AVG = []\n",
    "for cr in classification_test_performance:\n",
    "    F1_macro_AVG.append(cr['macro avg']['f1-score'])\n",
    "    F1_weighted_AVG.append(cr['weighted avg']['f1-score'])\n",
    "supports = [cf['macro avg']['support'] for cf in classification_test_performance]\n",
    "print(f'MEAN = {np.mean(F1_macro_AVG)}, WEIGHTED AVG = {np.sum([F1_macro_AVG[i]*supports[i] for i in range(0,len(F1_macro_AVG))])/(np.sum(supports))}, STDEV = {np.std(F1_macro_AVG)}')\n",
    "print(f'MEAN = {np.mean(F1_weighted_AVG)}, WEIGHTED AVG = {np.sum([F1_weighted_AVG[i]*supports[i] for i in range(0,len(F1_weighted_AVG))])/(np.sum(supports))}, STDEV = {np.std(F1_weighted_AVG)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [i for i in zip(F1_macro_AVG, F1_weighted_AVG, supports)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('resClust12fold.npy',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.659857511520386"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(prediction_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
